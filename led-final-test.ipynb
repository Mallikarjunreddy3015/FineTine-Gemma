{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7818455,"sourceType":"datasetVersion","datasetId":4570751},{"sourceType":"datasetVersion","sourceId":7829966,"datasetId":4588708}],"dockerImageVersionId":30665,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"887e2e5084eb47caab261d56a13acd4d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d64554d71a9248c1bb7a9f1beff26a8a","IPY_MODEL_25a0ee8e10014ef3bb544b9d2c22ec3d","IPY_MODEL_0d282c0798e44fe1a053cd99572ea365"],"layout":"IPY_MODEL_1980af72cb1c46e79fc05799ed40a7c6"}},"d64554d71a9248c1bb7a9f1beff26a8a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ea8c338077464045b8937dccb1efca93","placeholder":"​","style":"IPY_MODEL_dd571fe007f944a186f6126eebe30200","value":"Loading checkpoint shards: 100%"}},"25a0ee8e10014ef3bb544b9d2c22ec3d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_05938a88db5c4c14a5a4f7fa3268b6b7","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1ab87d4f3cdb4db69a66e01d9f89c404","value":2}},"0d282c0798e44fe1a053cd99572ea365":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_46811eb2e6a94dd49ea03da0816b38db","placeholder":"​","style":"IPY_MODEL_aaf613114b8f4a8c8a9b3c763c248518","value":" 2/2 [00:27&lt;00:00, 11.38s/it]"}},"1980af72cb1c46e79fc05799ed40a7c6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ea8c338077464045b8937dccb1efca93":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dd571fe007f944a186f6126eebe30200":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"05938a88db5c4c14a5a4f7fa3268b6b7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1ab87d4f3cdb4db69a66e01d9f89c404":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"46811eb2e6a94dd49ea03da0816b38db":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aaf613114b8f4a8c8a9b3c763c248518":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"beba8f83c60d48f09fad03abac52855b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b445dddd568b4aae9f5b0dec92957392","IPY_MODEL_d6a7f7012a1a41d4986b29283e9fd334","IPY_MODEL_7912f98ebd7948d7a17477e82a5c6919"],"layout":"IPY_MODEL_d32d0d086bdd40329e655f534ec0e7e7"}},"b445dddd568b4aae9f5b0dec92957392":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_286e319c6429456db233911c12ddfae9","placeholder":"​","style":"IPY_MODEL_6b9026cbeb484e949998abd3de212e2a","value":"Loading checkpoint shards:   0%"}},"d6a7f7012a1a41d4986b29283e9fd334":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_563eec2516f443b8ad730f93eb348212","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7056e62dfbf84a7fb2dc265f8635491b","value":0}},"7912f98ebd7948d7a17477e82a5c6919":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1eb8c6ed3f7c49c495068ecfa9d057a1","placeholder":"​","style":"IPY_MODEL_55f865371ee24c3b9a3619066f7a6ad9","value":" 0/2 [00:11&lt;?, ?it/s]"}},"d32d0d086bdd40329e655f534ec0e7e7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"286e319c6429456db233911c12ddfae9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6b9026cbeb484e949998abd3de212e2a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"563eec2516f443b8ad730f93eb348212":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7056e62dfbf84a7fb2dc265f8635491b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1eb8c6ed3f7c49c495068ecfa9d057a1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"55f865371ee24c3b9a3619066f7a6ad9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# import locale\n# locale.getpreferredencoding = lambda: \"UTF-8\"","metadata":{"id":"6IM63IJ447Sy"},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"!pip3 install -q -U transformers\n!pip3 install -q -U kaggle\n!pip3 install -q -U accelerate\n!pip3 install -q -U datasets\n","metadata":{"id":"6xEr2Wf2VEBm","execution":{"iopub.status.busy":"2024-03-13T04:31:46.227395Z","iopub.execute_input":"2024-03-13T04:31:46.227786Z","iopub.status.idle":"2024-03-13T04:33:03.506793Z","shell.execute_reply.started":"2024-03-13T04:31:46.227744Z","shell.execute_reply":"2024-03-13T04:33:03.505690Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 23.8.0 requires cubinlinker, which is not installed.\ncudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 23.8.0 requires ptxcompiler, which is not installed.\ncuml 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\napache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 15.0.1 which is incompatible.\nbeatrix-jupyterlab 2023.128.151533 requires jupyterlab~=3.6.0, but you have jupyterlab 4.1.2 which is incompatible.\ncudf 23.8.0 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.3.0 which is incompatible.\ncudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ncudf 23.8.0 requires protobuf<5,>=4.21, but you have protobuf 3.20.3 which is incompatible.\ncudf 23.8.0 requires pyarrow==11.*, but you have pyarrow 15.0.1 which is incompatible.\ncuml 23.8.0 requires dask==2023.7.1, but you have dask 2024.2.0 which is incompatible.\ndask-cudf 23.8.0 requires dask==2023.7.1, but you have dask 2024.2.0 which is incompatible.\ndask-cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nsecret_label = \"HF\"\nsecret_value = UserSecretsClient().get_secret(secret_label)\nfrom huggingface_hub import login\nlogin(token=secret_value)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uBnHQOYb-DGn","outputId":"03f284aa-5389-48c9-ff62-b2987034df4c","execution":{"iopub.status.busy":"2024-03-13T04:33:42.680155Z","iopub.execute_input":"2024-03-13T04:33:42.680849Z","iopub.status.idle":"2024-03-13T04:33:43.046205Z","shell.execute_reply.started":"2024-03-13T04:33:42.680811Z","shell.execute_reply":"2024-03-13T04:33:43.045272Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\nToken is valid (permission: write).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport pandas as pd\nfrom transformers import AutoTokenizer, AutoModelForCausalLM,GenerationConfig,LEDForConditionalGeneration","metadata":{"id":"Dp78nEbjVEBq","execution":{"iopub.status.busy":"2024-03-13T04:41:21.972183Z","iopub.execute_input":"2024-03-13T04:41:21.973054Z","iopub.status.idle":"2024-03-13T04:41:21.977384Z","shell.execute_reply.started":"2024-03-13T04:41:21.973022Z","shell.execute_reply":"2024-03-13T04:41:21.976393Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"model_id = \"/kaggle/input/finetuned-kaggle-100-ckpt/checkpoint-100\"\n\nfrom transformers import AutoTokenizer, LEDModel\nimport torch\n\ntokenizer = AutoTokenizer.from_pretrained(model_id)\nmodel = LEDForConditionalGeneration.from_pretrained(model_id).to(\"cuda:0\")\n","metadata":{"id":"XPSTaqhdVEBs","colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["887e2e5084eb47caab261d56a13acd4d","d64554d71a9248c1bb7a9f1beff26a8a","25a0ee8e10014ef3bb544b9d2c22ec3d","0d282c0798e44fe1a053cd99572ea365","1980af72cb1c46e79fc05799ed40a7c6","ea8c338077464045b8937dccb1efca93","dd571fe007f944a186f6126eebe30200","05938a88db5c4c14a5a4f7fa3268b6b7","1ab87d4f3cdb4db69a66e01d9f89c404","46811eb2e6a94dd49ea03da0816b38db","aaf613114b8f4a8c8a9b3c763c248518"]},"outputId":"621fcfa0-b94a-4c97-9f7c-26ded09d2a6e","execution":{"iopub.status.busy":"2024-03-13T04:42:28.943849Z","iopub.execute_input":"2024-03-13T04:42:28.944777Z","iopub.status.idle":"2024-03-13T04:42:29.426403Z","shell.execute_reply.started":"2024-03-13T04:42:28.944740Z","shell.execute_reply":"2024-03-13T04:42:29.425561Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def formatting_prompts_func(example):\n    words=len(example[\"Output\"].split())\n#     print(\"no of words : \" ,words)\n#     print(\"---------\"\n    return  f'summarize the following data in {words} words: {example[\"Input\"]}'\n","metadata":{"id":"z-lQ3yQ5edtp","execution":{"iopub.status.busy":"2024-03-13T04:45:28.678561Z","iopub.execute_input":"2024-03-13T04:45:28.679423Z","iopub.status.idle":"2024-03-13T04:45:28.684143Z","shell.execute_reply.started":"2024-03-13T04:45:28.679389Z","shell.execute_reply":"2024-03-13T04:45:28.683140Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"from datasets import load_dataset,Dataset\n\ndataset = load_dataset(\"zqz979/meta-review\", split=\"test\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MouJU5_A31QM","outputId":"362f7cec-f9f2-4bba-db48-5ee17f5cc592","execution":{"iopub.status.busy":"2024-03-13T04:36:00.820402Z","iopub.execute_input":"2024-03-13T04:36:00.821266Z","iopub.status.idle":"2024-03-13T04:36:16.275162Z","shell.execute_reply.started":"2024-03-13T04:36:00.821232Z","shell.execute_reply":"2024-03-13T04:36:16.274226Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/1.65k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"889ee8a0916540c4952a5097b62b6db3"}},"metadata":{}},{"name":"stderr","text":"Downloading data: 100%|██████████| 83.9M/83.9M [00:05<00:00, 15.8MB/s]\nDownloading data: 100%|██████████| 18.0M/18.0M [00:01<00:00, 10.5MB/s]\nDownloading data: 100%|██████████| 18.0M/18.0M [00:01<00:00, 10.5MB/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"516c9b60156e476bb134b09a5e79b58e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"adb3528f69214c87b3a407c8371de66e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"56f92e5ae37e4c89b6137462b9b4369b"}},"metadata":{}}]},{"cell_type":"code","source":"device = \"cuda:0\"\nencodeds = tokenizer(formatting_prompts_func(dataset[2]), return_tensors=\"pt\")\n\n\nmodel_inputs = encodeds.to(device)\n\ngenerated_ids = model.generate(**model_inputs)\ndecoded = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\nprint(decoded)","metadata":{"id":"pwHTQyL2VEBt","colab":{"base_uri":"https://localhost:8080/"},"outputId":"7079104f-fe92-49b4-d9dd-8e38f3efd113","execution":{"iopub.status.busy":"2024-03-13T04:44:02.019952Z","iopub.execute_input":"2024-03-13T04:44:02.020640Z","iopub.status.idle":"2024-03-13T04:44:06.198316Z","shell.execute_reply.started":"2024-03-13T04:44:02.020610Z","shell.execute_reply":"2024-03-13T04:44:06.197429Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"no of words :  111\n---------\nThis paper proposes to use Cluster Learnability (ID) and Cluster Learnable (CL) to evaluate the quality of self-supervised learning representations. The reviewers found that the proposed metrics are not sufficient to justify the proposed methods.    The reviewers also found that there was a lack of clarity on the experimental results.  The authors did not address the reviewers' concerns and the reviewers did not take into account the technical aspects of the paper. The authors have not addressed the reviewers’ concerns and concerns. \n","output_type":"stream"}]},{"cell_type":"code","source":"dataset","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U1uls2YC6bL3","outputId":"7ecc233b-6df2-46f9-9228-dabb169ac272","execution":{"iopub.status.busy":"2024-03-13T04:45:40.530262Z","iopub.execute_input":"2024-03-13T04:45:40.531098Z","iopub.status.idle":"2024-03-13T04:45:40.537538Z","shell.execute_reply.started":"2024-03-13T04:45:40.531063Z","shell.execute_reply":"2024-03-13T04:45:40.536538Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['Input', 'Output'],\n    num_rows: 1649\n})"},"metadata":{}}]},{"cell_type":"code","source":"original_model_id =\"allenai/led-base-16384\"\noriginal_tokenizer = AutoTokenizer.from_pretrained(original_model_id)\noriginal_model = LEDForConditionalGeneration.from_pretrained(original_model_id).to(\"cuda:1\")","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":457,"referenced_widgets":["beba8f83c60d48f09fad03abac52855b","b445dddd568b4aae9f5b0dec92957392","d6a7f7012a1a41d4986b29283e9fd334","7912f98ebd7948d7a17477e82a5c6919","d32d0d086bdd40329e655f534ec0e7e7","286e319c6429456db233911c12ddfae9","6b9026cbeb484e949998abd3de212e2a","563eec2516f443b8ad730f93eb348212","7056e62dfbf84a7fb2dc265f8635491b","1eb8c6ed3f7c49c495068ecfa9d057a1","55f865371ee24c3b9a3619066f7a6ad9"]},"id":"34dT5pOF8Zh3","outputId":"039463a4-8143-471d-ef7a-bb1ed3c348ec","execution":{"iopub.status.busy":"2024-03-13T04:48:59.908535Z","iopub.execute_input":"2024-03-13T04:48:59.908903Z","iopub.status.idle":"2024-03-13T04:49:06.350875Z","shell.execute_reply.started":"2024-03-13T04:48:59.908875Z","shell.execute_reply":"2024-03-13T04:49:06.350070Z"},"trusted":true},"execution_count":22,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/27.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"661a7c08c3914f96bcb469ccced34b12"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.09k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3e56ad5c07aa44f0803735add1200a41"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5dbe44348fa34b80808f1cadb532afcd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8014359c8b38478d884152e602abc436"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/772 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cd28e1e6f06e4365aa39c33457699ba0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/648M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2fac244bb08743348c18f27119e1cb9a"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/168 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"adebc507222d4c978740b9eb7af1c473"}},"metadata":{}}]},{"cell_type":"code","source":"# input_ids = tokenizer(dataset[0][\"Input\"], return_tensors=\"pt\").input_ids.to(\"cuda:1\")\n# original_model_outputs = original_model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=300),repetition_penalty=10.0)\n# original_model_text_output = original_tokenizer.decode(original_model_outputs[0], skip_special_tokens=True)","metadata":{"execution":{"iopub.status.busy":"2024-03-13T04:50:32.950975Z","iopub.execute_input":"2024-03-13T04:50:32.951423Z","iopub.status.idle":"2024-03-13T04:50:32.956184Z","shell.execute_reply.started":"2024-03-13T04:50:32.951393Z","shell.execute_reply":"2024-03-13T04:50:32.955092Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"raw_input = dataset[0:10]\nhuman_baseline_summaries = dataset[0:10]['Output']\n\noriginal_model_summaries = []\n\nled_model_summaries = []\n\nfor i in range(10):\n    words=len((dataset[i][\"Output\"]).split())\n    prompt1 =  f'summarize the following data in {words} words: {dataset[i][\"Input\"]}'\n\n    input_ids1 = tokenizer(prompt1, return_tensors=\"pt\").to(\"cuda:0\")\n    input_ids2 = original_tokenizer(dataset[i][\"Input\"], return_tensors=\"pt\").to(\"cuda:1\")\n    human_baseline_text_output = human_baseline_summaries[i]\n\n    \n    led_model_outputs = model.generate(**input_ids1)\n    led_model_text_output = tokenizer.decode(led_model_outputs[0], skip_special_tokens=True)\n    \n    original_model_outputs = original_model.generate(**input_ids2)\n    original_model_text_output = original_tokenizer.decode(original_model_outputs[0], skip_special_tokens=True)\n\n\n    original_model_summaries.append(original_model_text_output)\n\n    led_model_summaries.append(led_model_text_output)\n\nzipped_summaries = list(zip(human_baseline_summaries, original_model_summaries, led_model_summaries))\n\ndf = pd.DataFrame(zipped_summaries, columns = ['human_baseline_summaries', 'original_model_summaries', 'peft_model_summaries'])\ndf","metadata":{"id":"lozmVRSw31WU","execution":{"iopub.status.busy":"2024-03-13T05:06:14.666101Z","iopub.execute_input":"2024-03-13T05:06:14.666485Z","iopub.status.idle":"2024-03-13T05:07:06.739260Z","shell.execute_reply.started":"2024-03-13T05:06:14.666455Z","shell.execute_reply":"2024-03-13T05:07:06.738140Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stderr","text":"Input ids are automatically padded from 2686 to 3072 to be a multiple of `config.attention_window`: 1024\n/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1178: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\nInput ids are automatically padded from 2736 to 3072 to be a multiple of `config.attention_window`: 1024\nInput ids are automatically padded from 2332 to 3072 to be a multiple of `config.attention_window`: 1024\nInput ids are automatically padded from 1801 to 2048 to be a multiple of `config.attention_window`: 1024\nInput ids are automatically padded from 2612 to 3072 to be a multiple of `config.attention_window`: 1024\nInput ids are automatically padded from 1139 to 2048 to be a multiple of `config.attention_window`: 1024\nInput ids are automatically padded from 2033 to 2048 to be a multiple of `config.attention_window`: 1024\nInput ids are automatically padded from 537 to 1024 to be a multiple of `config.attention_window`: 1024\nInput ids are automatically padded from 1059 to 2048 to be a multiple of `config.attention_window`: 1024\nInput ids are automatically padded from 2017 to 2048 to be a multiple of `config.attention_window`: 1024\n","output_type":"stream"},{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"                            human_baseline_summaries  \\\n0  The paper present results using syntactic info...   \n1  The authors focus on large scale out-of-distri...   \n2  The problem studied in this paper is interesti...   \n3  The major criticism of this paper after the in...   \n4  This paper proposes a novel challenge setting:...   \n5  The paper explores generation of a volumetric ...   \n6  The paper introduces the new task of few-shot ...   \n7  This paper studies the computational benefits ...   \n8  The proposed approach exploits the color distr...   \n9  The paper proposes a variant of recurrent neur...   \n\n                            original_model_summaries  \\\n0  This paper is a very interesting paper. It is ...   \n1  The paper presents a large-scale evaluation of...   \n2  This paper tries to give a measurement method ...   \n3  This paper proposes a new gradient attack meth...   \n4  This work proposed to evaluate the robustness ...   \n5  The work tackles the problem of 3D scene gener...   \n6  agnostic segmentation networks with iterative ...   \n7  The paper considers the tasks of adversarial r...   \n8     ===========================================...   \n9  In this paper the authors propose a novel arch...   \n\n                                peft_model_summaries  \n0  This paper presents a new framework for addres...  \n1  The reviewers found that the paper is well wri...  \n2  This paper proposes to use Cluster Learnabilit...  \n3  This paper studies the problem of gradient att...  \n4  This paper investigates the robustness of Alph...  \n5  This paper presents a large scale scene genera...  \n6  This paper proposes a few-shot semantic edge d...  \n7  This paper studies adversarial robustness. The...  \n8  This paper introduces a new unrestricted adver...  \n9  This paper proposes a novel LSTM structure cal...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>human_baseline_summaries</th>\n      <th>original_model_summaries</th>\n      <th>peft_model_summaries</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>The paper present results using syntactic info...</td>\n      <td>This paper is a very interesting paper. It is ...</td>\n      <td>This paper presents a new framework for addres...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>The authors focus on large scale out-of-distri...</td>\n      <td>The paper presents a large-scale evaluation of...</td>\n      <td>The reviewers found that the paper is well wri...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>The problem studied in this paper is interesti...</td>\n      <td>This paper tries to give a measurement method ...</td>\n      <td>This paper proposes to use Cluster Learnabilit...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>The major criticism of this paper after the in...</td>\n      <td>This paper proposes a new gradient attack meth...</td>\n      <td>This paper studies the problem of gradient att...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>This paper proposes a novel challenge setting:...</td>\n      <td>This work proposed to evaluate the robustness ...</td>\n      <td>This paper investigates the robustness of Alph...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>The paper explores generation of a volumetric ...</td>\n      <td>The work tackles the problem of 3D scene gener...</td>\n      <td>This paper presents a large scale scene genera...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>The paper introduces the new task of few-shot ...</td>\n      <td>agnostic segmentation networks with iterative ...</td>\n      <td>This paper proposes a few-shot semantic edge d...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>This paper studies the computational benefits ...</td>\n      <td>The paper considers the tasks of adversarial r...</td>\n      <td>This paper studies adversarial robustness. The...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>The proposed approach exploits the color distr...</td>\n      <td>===========================================...</td>\n      <td>This paper introduces a new unrestricted adver...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>The paper proposes a variant of recurrent neur...</td>\n      <td>In this paper the authors propose a novel arch...</td>\n      <td>This paper proposes a novel LSTM structure cal...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"!pip3 install -q -U rouge_score\n!pip3 install -q -U evaluate\nimport evaluate\nrouge = evaluate.load('rouge')\n","metadata":{"execution":{"iopub.status.busy":"2024-03-13T05:03:38.052095Z","iopub.execute_input":"2024-03-13T05:03:38.052727Z","iopub.status.idle":"2024-03-13T05:04:19.510279Z","shell.execute_reply.started":"2024-03-13T05:03:38.052695Z","shell.execute_reply":"2024-03-13T05:04:19.509459Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n2024-03-13 05:04:07.449955: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-03-13 05:04:07.450052: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-03-13 05:04:07.618451: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b4f08d314c64a218688e91dbcfc53d6"}},"metadata":{}}]},{"cell_type":"code","source":"original_model_results = rouge.compute(\n    predictions=original_model_summaries,\n    references=human_baseline_summaries[0:len(original_model_summaries)],\n    use_aggregator=True,\n    use_stemmer=True,\n)\n\nled_model_summaries = rouge.compute(\n    predictions=led_model_summaries,\n    references=human_baseline_summaries[0:len(led_model_summaries)],\n    use_aggregator=True,\n    use_stemmer=True,\n)\n\nprint('ORIGINAL MODEL:')\nprint(original_model_results)\nprint('LED MODEL:')\nprint(led_model_summaries)","metadata":{"id":"I057VfIq-lSU","execution":{"iopub.status.busy":"2024-03-13T05:07:06.741036Z","iopub.execute_input":"2024-03-13T05:07:06.741380Z","iopub.status.idle":"2024-03-13T05:07:07.587750Z","shell.execute_reply.started":"2024-03-13T05:07:06.741351Z","shell.execute_reply":"2024-03-13T05:07:07.586701Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"ORIGINAL MODEL:\n{'rouge1': 0.10016438761209763, 'rouge2': 0.021009077142665797, 'rougeL': 0.07852940895224593, 'rougeLsum': 0.07867830373750495}\nLED MODEL:\n{'rouge1': 0.3256944249310342, 'rouge2': 0.08113142287139949, 'rougeL': 0.1914392524807772, 'rougeLsum': 0.19203892581924215}\n","output_type":"stream"}]}]}